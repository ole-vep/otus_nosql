### YC

Сделаем настройки и установки для работы с Яндекс Облаком
```
curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash
```
Необходимо получить OAuth-токен в сервисе Яндекс ID, затем делаем инит, выбираем облако, каталог для работы и зону доступности, в целом все согласно инструкции быстрого старта от YC
```
yc init
```
Проверить настройки профиля CLI:
```sh
$ yc config list
token: y0__wg....uI_Auth
cloud-id: b1ggpr45rv8mc57u7gaj
folder-id: b1gn6oqh12bkl5n5hepd
```

Дополнительные команды, посмотреть днс-зону, сети, подсети

```sh
$ yc dns zone list
+----------------------+--------------------------------------------+------------------+------------------------------+--------------------------------+
|          ID          |                    NAME                    |       ZONE       |          VISIBILITY          |          DESCRIPTION           |
+----------------------+--------------------------------------------+------------------+------------------------------+--------------------------------+
| dns71u2avh3o0kgijthm | auto-enphbkmhsb1u0jfdeu2a-internal_        | internal.        | PRIVATE enphbkmhsb1u0jfdeu2a | Automatically created DNS      |
|                      |                                            |                  |                              | zone "internal." for network   |
|                      |                                            |                  |                              | (enphbkmhsb1u0jfdeu2a)         |
| dns7v39fa6pgsm5u05ju | auto-enphbkmhsb1u0jfdeu2a-10_in-addr_arpa_ | 10.in-addr.arpa. | PRIVATE enphbkmhsb1u0jfdeu2a | Automatically created DNS zone |
|                      |                                            |                  |                              | "10.in-addr.arpa." for network |
|                      |                                            |                  |                              | (enphbkmhsb1u0jfdeu2a)         |
+----------------------+--------------------------------------------+------------------+------------------------------+--------------------------------+

$ yc vpc network list
+----------------------+---------+
|          ID          |  NAME   |
+----------------------+---------+
| enphbkmhsb1u0jfdeu2a | default |
+----------------------+---------+

$ yc vpc subnet list
+----------------------+-----------------------+----------------------+----------------+---------------+-----------------+
|          ID          |         NAME          |      NETWORK ID      | ROUTE TABLE ID |     ZONE      |      RANGE      |
+----------------------+-----------------------+----------------------+----------------+---------------+-----------------+
| e2ln1b7e9be36uhgi857 | default-ru-central1-b | enphbkmhsb1u0jfdeu2a |                | ru-central1-b | [10.129.0.0/24] |
| e9bdhk34mojus7h14feb | default-ru-central1-a | enphbkmhsb1u0jfdeu2a |                | ru-central1-a | [10.128.0.0/24] |
| fl8qc9b0epmupeeeb4k9 | default-ru-central1-d | enphbkmhsb1u0jfdeu2a |                | ru-central1-d | [10.130.0.0/24] |
+----------------------+-----------------------+----------------------+----------------+---------------+-----------------+
```
Сделаем ключ для SSH-доступа
```
ssh-keygen -t rsa -b 2048
```
Создадим парочку ВМ, посмотрим на список машин
```sh
yc compute instance create mg-node1 --ssh-key .ssh/id_rsa.pub --create-boot-disk image-folder-id=standard-images,image-family=ubuntu-2204-lts,size=30 --network-interface subnet-name=default-ru-central1-d,nat-ip-version=ipv4 --memory 4G --cores 2 --zone ru-central1-d --hostname mg-node1 
...
yc compute instance create ch-node2 --ssh-key .ssh/id_rsa.pub --create-boot-disk image-folder-id=standard-images,image-family=ubuntu-2204-lts,size=30 --network-interface subnet-name=default-ru-central1-d,nat-ip-version=ipv4 --memory 4G --cores 2 --zone ru-central1-d --hostname ch-node2
...

yc compute instance list
+----------------------+----------+---------------+---------+-----------------+-------------+
|          ID          |   NAME   |    ZONE ID    | STATUS  |   EXTERNAL IP   | INTERNAL IP |
+----------------------+----------+---------------+---------+-----------------+-------------+
| fv42huljnod7mtrgv6hr | ch-node2 | ru-central1-d | RUNNING | 158.160.158.180 | 10.130.0.20 |
| fv4oi8gbb67isr3ntm8d | mg-node1 | ru-central1-d | RUNNING | 84.201.169.125  | 10.130.0.24 |
+----------------------+----------+---------------+---------+-----------------+-------------+
```
Скачаем дата-сет, набор данных кулинарных рецептов https://recipenlg.cs.put.poznan.pl/dataset
и скопируем на обе машины
```
scp /drives/C/Users/vov/Desktop/dataset.zip yc-user@158.160.158.180:/home/yc-user
scp /drives/C/Users/vov/Desktop/dataset.zip yc-user@84.201.169.125:/home/yc-user

```
### MongoDB

Поработаем с vm для монго
```sh
ssh yc-user@84.201.169.125
```
Распакуем датасет и получаем файл full_dataset.csv, размером 2.2 GB
```sh
sudo apt install zip unzip -y
unzip dataset.zip
```sh
Установка Монго
```sh
sudo apt-get install gnupg curl
curl -fsSL https://www.mongodb.org/static/pgp/server-8.1.asc |    sudo gpg -o /usr/share/keyrings/mongodb-server-8.1.gpg    --dearmor
echo "deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-8.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/8.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-8.0.list
sudo apt-get update
sudo apt-get install -y mongodb-org

sudo systemctl start mongod.service
```

Импортируем датасет
```sh
yc-user@mg-node1:~$ mongoimport --host=127.0.0.1 -d test -c recipes --type csv --file dataset/full_dataset.csv --headerline

2025-01-22T16:47:18.625+0000    connected to: mongodb://127.0.0.1/
2025-01-22T16:47:21.626+0000    [........................] test.recipes 31.7MB/2.14GB (1.4%)
2025-01-22T16:47:24.625+0000    [........................] test.recipes 53.7MB/2.14GB (2.5%)
2025-01-22T16:47:27.630+0000    [........................] test.recipes 74.1MB/2.14GB (3.4%)
2025-01-22T16:47:30.626+0000    [........................] test.recipes 91.1MB/2.14GB (4.2%)
2025-01-22T16:47:33.625+0000    [#.......................] test.recipes 102MB/2.14GB (4.7%)
...
2025-01-22T16:53:03.625+0000    [#######################.] test.recipes 2.14GB/2.14GB (99.9%)
2025-01-22T16:53:03.735+0000    [########################] test.recipes 2.14GB/2.14GB (100.0%)
2025-01-22T16:53:03.758+0000    2231142 document(s) imported successfully. 0 document(s) failed to import.
```
Импорт выполнялся 6 минут

Проверим количество записей запросом
```
test> db.recipes.countDocuments({})
2231142
```
Кстати, это пока без индексов и статистика по запросам не включена, запрос выполнялся довольно долго - около минуты.

Влючим сбор статистики по запросам, профилирование
```
db.getProfilingStatus()
{ was: 0, slowms: 100, sampleRate: 1, ok: 1 }
test> db.setProfilingLevel(1)
{ was: 0, slowms: 100, sampleRate: 1, ok: 1 }
test>  db.getProfilingStatus()
{ was: 1, slowms: 100, sampleRate: 1, ok: 1 }
```
Запустим запрос, который выдаёт самый длинный рецепт, содержащий в интгредиентах ginger(имбирь) - выдаёт нам рецепт, который называется 'Moon Cakes'
```sh
test> db.recipes.aggregate([{ $match: {"NER" : /ginger/} },{$project:{_id: 0,title:1,NER: 1,length_N: { $strLenCP: "$NER" },directions: 1,length_d: { $strLenCP: "$directions" }}},{$sort:{length_d:-1}},{$limit:1}])
[
  {
    title: 'Moon Cakes',
    directions: '["In a small saucepan, combine the sugar, citric acid, and water and let stand for 30 minutes.", "Then bring the mixture to ...,
    NER: '["sugar", "citric", "water", "Eggs", "pork fatback", "Siu", "Chinese sweet sausage", "powdered sugar", "sunflower seeds", "walnuts", "cashews", "almonds", "sesame seeds", "ginger", "candied citron", "chicken", "sugar", "light corn syrup", "Chinese sorghum", "freshly grated lime zest", "canola", "Caramel Sauce", "bicarbonate solution", "Sugar syrup", "flour", "egg yolks", "Caramel Sauce"]',
    length_N: 390,
    length_d: 14822
  }
]
# само поле directions отредактировал список действий, чтобы не загромождать вывод тут
```

Посмотрим проекции на интересные поля в специальной системной коллекции для профилирования запросов с фильтрами интересующей нас коллекции компаний и для запросов дольше 300 мс
```sh
test> db.system.profile.find({$and: [{millis : {$gte : 300} }, {ns: 'test.recipes'}]}, {nreturned:1,millis:1,responseLength:1,cpuNanos:1,planSummary:1,planningTimeMicros:1,keysExamined:1,docsExamined:1})
[
  {
    keysExamined: 0,
    docsExamined: 2231142,
    nreturned: 1,
    responseLength: 15398,
    cpuNanos: Long('4753647631'),
    millis: 4755,
    planSummary: 'COLLSCAN',
    planningTimeMicros: 123
  }
]
```
Запрос использует последовательно сканирование коллекции и выполняется за 4,755 секунды.

### ClickHouse

Поработаем с vm для кликхауса
```sh
ssh yc-user@158.160.158.180
```
Распакуем датасет и получаем файл full_dataset.csv, размером 2.2 GB
```sh
sudo apt install zip unzip -y
unzip dataset.zip
```

Установим CH на машинку
```sh
sudo apt-get install -y apt-transport-https ca-certificates curl gnupg
curl -fsSL 'https://packages.clickhouse.com/rpm/lts/repodata/repomd.xml.key' | sudo gpg --dearmor -o /usr/share/keyrings/clickhouse-keyring.gpg

echo "deb [signed-by=/usr/share/keyrings/clickhouse-keyring.gpg] https://packages.clickhouse.com/deb stable main" | sudo tee \
    /etc/apt/sources.list.d/clickhouse.list
sudo apt-get update
sudo apt-get install -y clickhouse-server clickhouse-client
...
#Задали пароль на этом шаге ch_2412347
```

Стартуем сервер, проверяем вход, используя пароль. Создадим таблицу
```sh
sudo service clickhouse-server start
clickhouse-client --password='ch_2412347'

CREATE TABLE recipes
(
    `title` String,
    `ingredients` Array(String),
    `directions` Array(String),
    `link` String,
    `source` LowCardinality(String),
    `NER` Array(String)
)
ENGINE = MergeTree
ORDER BY title

Query id: 26c8f137-cb89-4a39-9082-be6a03f27626

Ok.

0 rows in set. Elapsed: 0.059 sec.
```
Импортируем датасет
```sh
yc-user@ch-node2:~$ clickhouse-client --query "
    INSERT INTO recipes
    SELECT
        title,
        JSONExtract(ingredients, 'Array(String)'),
        JSONExtract(directions, 'Array(String)'),
        link,
        source,
        JSONExtract(NER, 'Array(String)')
    FROM input('num UInt32, title String, ingredients String, directions String, link String, source LowCardinality(String), NER String')
    FORMAT CSVWithNames
" --input_format_with_names_use_header 0 --format_csv_allow_single_quote 0 --input_format_allow_errors_num 10 --password='ch_2412347' < dataset/full_dataset.csv
```
3 минуты выполнялась вставка (у монго было 6 минут)

Проверим количество записей запросом
```
ch-node2.ru-central1.internal :) SELECT count() FROM recipes;

SELECT count()
FROM recipes

Query id: 38d0b212-f589-4c03-8eda-4d4a59488e6f

   ┌─count()─┐
1. │ 2231142 │ -- 2.23 million
   └─────────┘

1 row in set. Elapsed: 0.003 sec.

```
Почти моментально, против 1 минуты у монгоДБ

Ну и наконец, посмотрим сколько будет выполняться наш тестовый запрос, выводящий самый длинный рецепт с имбирем.
```sh
ch-node2.ru-central1.internal :) 

SELECT
    title,
    directions,
    NER,
    length(NER),
    length(directions)
FROM recipes
WHERE has(NER, 'ginger')
ORDER BY length(directions) DESC
LIMIT 1

Query id: 26772272-5da2-4734-a6d9-4bebb795d5e2

   ┌─title──────┬─directions─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─NER────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬─length(NER)─┬─length(directions)─┐
1. │ Moon Cakes │ ['In a small saucepan, combine the sugar, citric acid, and water and let stand for 30 minutes.','Then bring the mixture to ⋯│ ['sugar','citric','water','Eggs','pork fatback','Siu','Chinese sweet sausage','powdered sugar','sunflower seeds','walnuts','cashews','almonds','sesame seeds','ginger','candied citron','chicken','sugar','light corn syrup','Chinese sorghum','freshly grated lime zest','canola','Caramel Sauce','bicarbonate solution','Sugar syrup','flour','egg yolks','Caramel Sauce'] │          27 │                164 │
   └────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴─────────────┴────────────────────┘

1 row in set. Elapsed: 1.435 sec. Processed 2.23 million rows, 1.65 GB (1.55 million rows/s., 1.15 GB/s.)
Peak memory usage: 29.20 MiB.

```
1.435 Секунды, против  4,755 на Mongo

Таким образом, именно на этом датасете Кликхаус быстрее Монго справился и со вставкой датасета и быстрее оказался на запросах.